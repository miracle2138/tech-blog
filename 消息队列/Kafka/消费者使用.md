# 消费者使用

## 使用方法
在代码层面，分为以下几步：
1. 创建客户端
2. 订阅主题
3. poll拉取消息
4. 提交位移
5. 关闭client

### 创建客户端
类似生产者，需要指定指定消费参数
```
    public static Properties initConfig(){
        Properties props = new Properties();
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringDeserializer");
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,
                "org.apache.kafka.common.serialization.StringDeserializer");
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);
        props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
        props.put(ConsumerConfig.CLIENT_ID_CONFIG, "client.id.demo");
        return props;
    }
    
    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
```

### 订阅
```
consumer.subscribe(Arrays.asList(topic1));
```
多次调用以最后一次为准，而不是并集

### poll拉取消息
```
ConsumerRecords<String, String> records = 
         consumer.poll(Duration.ofMillis(1000));
for (TopicPartition tp : records.partitions()) {
    for (ConsumerRecord<String, String> record : records.records(tp)) {
        System.out.println(record.partition()+" : "+record.value());
    }
}
```

### 提交位移
Kafka消费使用的是pull模型，每一次poll时消息的位置是在Broker端记录的。从Broker端记录的好处是，客户端
发生重启或者更换实例，新的消费者加入集群仍旧能知道对该分区的消费位移信息，不回因为消费者的宕机。重启二丢失。
既然消费位置是记录在Broker端的，那就需要消费者自动上报位移，也叫提交位移。

提交位移很复杂。可能导致两种问题：1）重复消费；2）消息丢失
- 重复消费：poll下一批消息，先执行业务消费逻辑，再提交位移。如果消费完了，提交位移失败。
  下一次再poll时会拉到重复的消息。
- 消息丢失：poll下一批消息，先提交再执行业务消费逻辑。如果提交完，消费消息失败，下一次
  再poll时，会从新的位移开始，之前那批还没有消费的消息就会丢失。

经验上，重复消费+业务侧幂等是最佳实践。最差不能丢消息，重复消费可以通过幂等手段来避免。

位移提交方式：
Kafka提供了自动位移提交和手动位移提交两种方式。

#### 自动位移提交
Kafka位移提交的默认方式，当参数`enable.auto.commit`为true时生效。自动移交位移也不是每一次拉取都提交，而是间隔
一段时间才将已经拉取的最大位移提交，这个时间由参数`auto.commit.interval.ms`指定，默认5s。如果打到了自动位移提交的时机，
在poll请求时就会带上位移信息。
自动提交的优点是使用简单，消费者不用关注提交细节。缺点是可能发生重复消费。比如消费了100条消息还没有大提交时间，突然宕机，
就会导致位移丢失，下一次poll时会重复拉取消息。如果特别在意，可以采用手动提交方式。

#### 手动位移提交
手动提交也有两种方式：1）同步；2）异步

##### 同步提交
有两种API：
```
public void commitSync()
```
粗粒度的位移提交，默认为poll下来的消息的最大位移+1，无法设置分区以及位移
例子：
```java
while (isRunning.get()) {
    ConsumerRecords<String, String> records = consumer.poll(1000);
    for (ConsumerRecord<String, String> record : records) {
        //do some logical processing.
    }
    consumer.commitSync();
}
```

粗粒度的提交，只能以poll的消息的最大位移来提交，不能定制。
细粒度位移提交，可以指定提交位移的offset以及分区。
```
public void commitSync(final Map<TopicPartition, OffsetAndMetadata> offsets)
```
例子：
```
//代码清单11-3 按分区粒度同步提交消费位移
try {
    while (isRunning.get()) {
        ConsumerRecords<String, String> records = consumer.poll(1000);
        for (TopicPartition partition : records.partitions()) {
            List<ConsumerRecord<String, String>> partitionRecords =
                    records.records(partition);
            for (ConsumerRecord<String, String> record : partitionRecords) {
                //do some logical processing.
            }
            long lastConsumedOffset = partitionRecords
                    .get(partitionRecords.size() - 1).offset();
            consumer.commitSync(Collections.singletonMap(partition,
                    new OffsetAndMetadata(lastConsumedOffset + 1)));
        }
    }
} finally {
    consumer.close();
}
```
同步位移提交是阻塞式的，会降低吞吐量。为避免这个问题，可以采用异步提交。

##### 异步提交
例子：
```
while (isRunning.get()) {
    ConsumerRecords<String, String> records = consumer.poll(1000);
    for (ConsumerRecord<String, String> record : records) {
        //do some logical processing.
    }
    consumer.commitAsync(new OffsetCommitCallback() {
        @Override
        public void onComplete(Map<TopicPartition, OffsetAndMetadata> offsets,
                               Exception exception) {
            if (exception == null) {
                System.out.println(offsets);
            }else {
                log.error("fail to commit offsets {}", offsets, exception);
            }
        }
    });
}
```

### 关闭消费者
当消费结束或者有异常导致退出，需要关闭消费者，归还占用的资源。
例子：
```
consumer.subscribe(Arrays.asList(topic));
try {
    while (running.get()) {
        //consumer.poll(***)
        //process the record.
        //commit offset.
    }
} catch (WakeupException e) {
    // ingore the error
} catch (Exception e){
    // do some logic process.
} finally {
    // maybe commit offset.
    consumer.close();
}
```

## 多线程消费
需要注意的是
***KafkaProducer是线程安全的，然后KafkaConsumer是线程不安全的***

Kafka客户端限制一个KafkaConsumer实例只能被一个线程使用，如果多线程并发使用会抛出异常。
这个机制是通过加锁实现的：
```
private void acquire() {
    long threadId = Thread.currentThread().getId();
    if (threadId != currentThread.get() &&
            !currentThread.compareAndSet(NO_CURRENT_THREAD, threadId))
        throw new ConcurrentModificationException
                ("KafkaConsumer is not safe for multi-threaded access");
    refcount.incrementAndGet();
}
```
Kafka的任何操作都需要先调用acquire方法获取到锁。

既然KafkaConsumer是单线程的，那会不会影响消费的吞吐量？其实还是有多线程使用的办法的。

### 多消费线程
一个多消费线程，就代表一个KafkaConsumer实例，也代表一个消费者。所以消费者是线程维度的，假设有5个分区，那么最多可以有5个
消费线程。KafkaConsumer个数受分区数限制。我们自然可以通过创建多个KafkaConsumer实例来并发消费。
这种方案本质上就是起了多个消费者。

### 单消费线程+worker线程池
一个KafkaConsumer实例负责拉取消息，将消息放入线程池进行消费。这种方式进一步提升了并发能力，打破了
分区数的限制。但是缺点在于会导致消息乱序消费并且位移提交很难控制。

- 消息乱序问题可以通过将消息key映射到线程的方式解决；
- 位移提交则需要维护一个全局位移变量，防止位移覆盖。这里的问题是搞不好会消息丢失。比如0-99的消息在
线程1消费，比价慢，100-200的消息在线程2消费，处理的比较块，进行了提交，则位移为200。消费者宕机，
0-99的消息没有被消费完但是已经拉不到了。所以提交位移时不能按照最大的位移提交，而是确保要提交
的位移之前的消息确实已经被消费完了才能提交，有点类似TCP的消息确认机制，需要维护一个窗口。

### 综合方式
我见到的大公司的最佳实践：一个KafkaConsumer实例代表一个物理进程，进程内部采用线程池方式消费消息。



## 参考
[0](https://juejin.cn/book/6844733793220165639/section/6844733793631207438)
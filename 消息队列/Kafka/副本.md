# 副本

## 副本概念
Kafka采用冗余的方式提升集群的可靠性。也即每一个分区都有多个副本。
Kafka中只有leader副本能够提供读写，follower副本只能同步日志，作为冷备。当leader副本失效后，follower副本选举成为新的leader。
Kafka中日志同步有几个核心概念：
- AR：某一个分区的所有副本节点。
- ISR：代表与leader同步的副本节点。
- LEO：指的是副本同步到的消息的下一个偏移量。LEO可以代表某一个节点同步到的数据的新旧程度。
- HW：ISR中最小的LEO。代表集群中可读的消息位移。consumer端只能读到HW之前的消息。

## ISR
什么叫做与leader同步的状态？
如果一个follower节点数据落后leader太多，这个follower就会被从ISR中移除，是一个失效的节点。这样的节点如果被后续选主，会导致数据不一致。
那么如何界定"数据落后太多"？
Kafka有一个参数`replica.lag.time.max.ms`，用于指定follower落后leader的ms数，如果超过这个数就会被移出ISR集合。
如何计算一个follower节点的落后时间？
`lagtime = now - lastCaughtUpTimeMs`
lastCaughtUpTimeMs代表上一次和leader保持同步的时间。这个时间由follower节点每一次从leader拉取数据时更新，如果当前拉取的数据是leader返回的那一个时间点的最新数据，
就会在response里告知follower，follower就会更新自己的lastCaughtUpTimeMs。很显然，如果follower落后太多，leader同步数据时就可能没有到达leader的LEO，此时follower就无法更新lastCaughtUpTimeMs。

Kafka会有定时任务检测每一个分区的副本lastCaughtUpTimeMs数据，如果检测到lastCaughtUpTimeMs数据超过或不足阈值，就会在zk上注册通知事件。
集群的控制器节点会watch这个节点，从而知道变更集群信息，修改集群信息并通知响应的Broker节点。

## 数据一致性
只有HW之前的消息可以被读取，leader节点失效后，新的leader只能从ISR中选中，也可以保证包含HW之前的全部数据。所以对于consumer而言读到的数据是一致的。
至于HW之后的数据，会被覆盖。也就是丢失。
对于producer端而言，如果没有配置acks=all，可能会发生消息丢失的情况。
如果配置了acks=all，只要返回了ACK，就意味着消息同步给ISR所有节点，那么这条消息就肯定不会丢失，是可以被consumer读到的。

## 关于读写分离
Kafka的所有读写操作只能由leader节点完成，为什么不提供读写分离？
Kafka是可以提供的，但是会增加系统的复杂度。并且更重要的是Kafka有自己的哲学，它使用分区副本的方式实现了集群的负载均衡。
我们看一个分区，它的流量都在leader节点。但是我们看Broker节点，其上会均衡分布不同主题不同分区的leader节点，那么这个Broker可以认为是负载均衡的，
从而整个集群也能认为是负载均衡的。当然这个理论依赖所有分区流量的均衡性。
# 生产者使用

## 使用方法
在代码层面，分为以下几步：
1. 创建客户端；
2. 发送消息；
3.关闭client；

### 创建客户端
```java
public class KafkaProducerAnalysis {
    public static final String brokerList = "localhost:9092";
    public static final String topic = "topic-demo";

    public static Properties initConfig(){
        Properties props = new Properties();
        props.put("bootstrap.servers", brokerList);
        props.put("key.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer",
                "org.apache.kafka.common.serialization.StringSerializer");
        props.put("client.id", "producer.client.id.demo");
        return props;
    }

    public static void main(String[] args) {
        Properties props = initConfig();
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        // use producer to send message
    }
}
```
- KafkaProducer是线程安全的对象。Kafka客户端的参数很多，这里只介绍最基本的，后面介绍其他参数
- bootstrap.servers用于指定kafka broker集群的地址，不需要全部，最佳实践是至少两个
- key.serializer 和 value.serializer：指定消息和key的序列化器，因为最终发送的是字节流

### 发送消息
每一条Kafka的消息，需要封装为`ProducerRecord`对象才能发送
发送API
```java
public Future<RecordMetadata> send(ProducerRecord<K, V> record)
public Future<RecordMetadata> send(ProducerRecord<K, V> record, 
                                   Callback callback)
```
从使用角度，Kafka客户端发送消息有三种方式：1）不关心返回值；2）同步；3）异步回调 

#### 不关心返回值
直接调用第一种格式的send方法，这种方式性能最高，但是没有关注发送结果，可能丢消息

#### 同步
send方法返回的是Future对象，可以通过调用其get方法同步阻塞获取发送结果
```
try {
    Future<RecordMetadata> future = producer.send(record);
    RecordMetadata metadata = future.get();
    System.out.println(metadata.topic() + "-" +
            metadata.partition() + ":" + metadata.offset());
} catch (ExecutionException | InterruptedException e) {
    e.printStackTrace();
}
```
如果发送失败，可以对出错的消息进行记录，进而重试

#### 异步回调
```java
producer.send(record, new Callback() {
    @Override
    public void onCompletion(RecordMetadata metadata, Exception exception) {
        if (exception != null) {
            exception.printStackTrace();
        } else {
            System.out.println(metadata.topic() + "-" +
                    metadata.partition() + ":" + metadata.offset());
        }
    }
});
```
采用同步阻塞方式，性能会下降；推荐异步回调，不会影响主调方的性能。在编程模型上也更加友好。

### 关闭client
```
producer.close();
```

## 分区
Kafka的每一个主题都会分为若干分区。发送消息时，Kafka客户端需要知道发往主题的哪一个分区。
先看一下ProducerRecord：
```
public class ProducerRecord<K, V> {
    private final String topic; //主题
    private final Integer partition; //分区号
    private final Headers headers; //消息头部
    private final K key; //键
    private final V value; //值
    private final Long timestamp; //消息的时间戳
    //省略其他成员方法和构造方法
}
```
选择分区的逻辑如下：
- 如果指定了partition，就按照指定的来。
- 如果没有指定partition，但是有key，会尝试根据key计算分区。计算逻辑为：根据key计算hash值，再根据hash值模分区数得到分区，所以相同key的消息会发往相同的分区。在实际业务使用时也建议指定key。
- 如果key都没有指定，第一次调用时随机生成一个整数（后面每次调用在这个整数上自增），将这个值与 topic 可用的 partition 总数取余得到 partition 值，也就是常说的 round-robin 算法。

## 拦截器
Kafka生产者和消费者都有拦截器，这里介绍生产者的拦截器。生产者的拦截器作用如下：
- 消息发送前回调
- 消息发送后收到响应回调

通过上述两个植入点，业务可以做一些通用逻辑处理，比如消息内容统一处理、统计、日志等操作
接口定义：
```
public ProducerRecord<K, V> onSend(ProducerRecord<K, V> record);
public void onAcknowledgement(RecordMetadata metadata, Exception exception);
```

## 重要参数
### acks
该参数代表消息写入多少副本才算成功。有三种取值：
- acks=1：代表写入leader区分就认为成功。可能出现leader节点还没来得及将消息复制到从节点就挂了导致的消息丢失。
- acks=0：代表不管发送结果。性能最好，也最易丢消息。
- acks=-1或者acksall：代表消息写入所有IRS副本才算成功。

### min.insync.replicas
该参数表示ISR最小副本数。与acks搭配使用保证消息不丢失。举个例子，如果acks=all，min.insync.replicas=2，此时集群ISR副本数为1，则写入不成功，因为要求至少写入2个副本。
如果acks=all，min.insync.replicas=2，此时集群ISR副本数为3，则即使写入2个副本也不行，因为min.insync.replicas代表的是集群ISR最小数目。

这两个参数需要搭配使用。

## 参考
[0](https://juejin.cn/book/6844733793220165639/section/6844733793618640903)
[1](https://juejin.cn/post/6857514628516315149)